{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "_QnW5xJpRE77",
    "outputId": "3df7d63a-a764-4dd4-ebb7-3e012183fe12"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first objective is to subset the data by keeping only data from europe and to add among the european countries, those with more data and with less variability. We assume missing at random and we are not imputing data here. It is assumed that the data of 2024 in terms of salaries will be inflated by 3%. This is not entirely true as we know this year the job market is cooling down in Europe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "collapsed": true,
    "id": "Ce1Shggs-jQG",
    "outputId": "18600f3a-bbed-492b-913f-6574d83c5542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            job_skills1                                                                                                  job_skills\n",
      "0                                                                                  None                                                                                                        None\n",
      "1                                            [r, python, sql, nosql, power bi, tableau]                                                      ['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']\n",
      "2                   [python, sql, c#, azure, airflow, dax, docker, kubernetes, jenkins]                       ['python', 'sql', 'c#', 'azure', 'airflow', 'dax', 'docker', 'kubernetes', 'jenkins']\n",
      "3                          [python, c++, java, matlab, aws, tensorflow, keras, pytorch]                                ['python', 'c++', 'java', 'matlab', 'aws', 'tensorflow', 'keras', 'pytorch']\n",
      "4                    [bash, python, oracle, aws, ansible, puppet, jenkins, gitlab, git]                        ['bash', 'python', 'oracle', 'aws', 'ansible', 'puppet', 'jenkins', 'gitlab', 'git']\n",
      "5                                                                    [python, sql, gcp]                                                                                    ['python', 'sql', 'gcp']\n",
      "6                                [sql, python, java, sql server, gcp, bigquery, hadoop]                                        ['sql', 'python', 'java', 'sql server', 'gcp', 'bigquery', 'hadoop']\n",
      "7  [sql, nosql, gcp, azure, aws, bigquery, databricks, redshift, airflow, kafka, spark]  ['sql', 'nosql', 'gcp', 'azure', 'aws', 'bigquery', 'databricks', 'redshift', 'airflow', 'kafka', 'spark']\n",
      "8                                                         [excel, powerpoint, power bi]                                                                         ['excel', 'powerpoint', 'power bi']\n",
      "9  [sql, python, r, mongodb, mongodb, sql server, azure, pandas, spark, windows, excel]  ['sql', 'python', 'r', 'mongodb', 'mongodb', 'sql server', 'azure', 'pandas', 'spark', 'windows', 'excel']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785741 entries, 0 to 785740\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   job_title_short        785741 non-null  object \n",
      " 1   job_title              785740 non-null  object \n",
      " 2   job_location           784696 non-null  object \n",
      " 3   job_via                785733 non-null  object \n",
      " 4   job_schedule_type      773074 non-null  object \n",
      " 5   job_work_from_home     785741 non-null  bool   \n",
      " 6   search_location        785741 non-null  object \n",
      " 7   job_posted_date        785741 non-null  object \n",
      " 8   job_no_degree_mention  785741 non-null  bool   \n",
      " 9   job_health_insurance   785741 non-null  bool   \n",
      " 10  job_country            785692 non-null  object \n",
      " 11  salary_rate            33067 non-null   object \n",
      " 12  salary_year_avg        22003 non-null   float64\n",
      " 13  salary_hour_avg        10662 non-null   float64\n",
      " 14  company_name           785723 non-null  object \n",
      " 15  job_skills             668704 non-null  object \n",
      " 16  job_type_skills        668704 non-null  object \n",
      " 17  job_skills1            668704 non-null  object \n",
      "dtypes: bool(3), float64(2), object(13)\n",
      "memory usage: 92.2+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3777320 entries, 0 to 3777319\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   job_title_short        object \n",
      " 1   job_title              object \n",
      " 2   job_location           object \n",
      " 3   job_via                object \n",
      " 4   job_schedule_type      object \n",
      " 5   job_work_from_home     bool   \n",
      " 6   search_location        object \n",
      " 7   job_posted_date        object \n",
      " 8   job_no_degree_mention  bool   \n",
      " 9   job_health_insurance   bool   \n",
      " 10  job_country            object \n",
      " 11  salary_rate            object \n",
      " 12  salary_year_avg        float64\n",
      " 13  salary_hour_avg        float64\n",
      " 14  company_name           object \n",
      " 15  job_skills             object \n",
      " 16  job_type_skills        object \n",
      " 17  job_skills1            object \n",
      "dtypes: bool(3), float64(2), object(13)\n",
      "memory usage: 443.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "      <th>job_skills1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee México</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job_title_short                                          job_title  \\\n",
       "0  Senior Data Engineer  Senior Clinical Data Engineer / Principal Clin...   \n",
       "1          Data Analyst                                       Data Analyst   \n",
       "\n",
       "                   job_location           job_via job_schedule_type  \\\n",
       "0                 Watertown, CT   via Work Nearby         Full-time   \n",
       "1  Guadalajara, Jalisco, Mexico  via BeBee México         Full-time   \n",
       "\n",
       "   job_work_from_home       search_location      job_posted_date  \\\n",
       "0               False  Texas, United States  2023-06-16 13:44:15   \n",
       "1               False                Mexico  2023-01-14 13:18:07   \n",
       "\n",
       "   job_no_degree_mention  job_health_insurance    job_country salary_rate  \\\n",
       "0                  False                 False  United States        None   \n",
       "1                  False                 False         Mexico        None   \n",
       "\n",
       "   salary_year_avg  salary_hour_avg                company_name  \\\n",
       "0              NaN              NaN        Boehringer Ingelheim   \n",
       "1              NaN              NaN  Hewlett Packard Enterprise   \n",
       "\n",
       "                                          job_skills  \\\n",
       "0                                               None   \n",
       "1  ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "\n",
       "                                     job_type_skills job_skills1  \n",
       "0                                               None        None  \n",
       "1  {'analyst_tools': ['power bi', 'tableau'], 'pr...           r  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Data\n",
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "\n",
    "# Loading Data\n",
    "b = load_dataset('lukebarousse/data_jobs')\n",
    "c = b['train'].to_pandas()\n",
    "d =c.copy()\n",
    "d['job_skills1']=d['job_skills'].apply(lambda x: ast.literal_eval(x) if pd.notna(x)  else x )\n",
    "print(d[ ['job_skills1','job_skills'] ].head(10).to_string())\n",
    "\n",
    "\n",
    "print(d.info())\n",
    "e=d.explode('job_skills1', ignore_index=True).copy()\n",
    "e.info()\n",
    "e.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sp1XWkreNnR",
    "outputId": "b26c6383-fc3a-47f1-8108-4d0605627548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Job  Salary                      Location               Via   Home                  DTC  Rate                     Company                                              job_skills  Skills        Country\n",
      "0  Senior Data Engineer     NaN                 Watertown, CT   via Work Nearby  False  2023-06-16 13:44:15  None        Boehringer Ingelheim                                                    None    None  United States\n",
      "1          Data Analyst     NaN  Guadalajara, Jalisco, Mexico  via BeBee México  False  2023-01-14 13:18:07  None  Hewlett Packard Enterprise  ['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']       r         Mexico\n",
      "2          Data Analyst     NaN  Guadalajara, Jalisco, Mexico  via BeBee México  False  2023-01-14 13:18:07  None  Hewlett Packard Enterprise  ['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']  python         Mexico\n",
      "3          Data Analyst     NaN  Guadalajara, Jalisco, Mexico  via BeBee México  False  2023-01-14 13:18:07  None  Hewlett Packard Enterprise  ['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']     sql         Mexico\n",
      "4          Data Analyst     NaN  Guadalajara, Jalisco, Mexico  via BeBee México  False  2023-01-14 13:18:07  None  Hewlett Packard Enterprise  ['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']   nosql         Mexico\n"
     ]
    }
   ],
   "source": [
    "# keeping selecter columns and rename\n",
    "f=e[ ['job_title_short'   , 'salary_year_avg','job_location', 'job_via',                'job_work_from_home', 'job_posted_date', 'salary_rate',     'company_name' ,'job_skills', 'job_skills1', 'job_country'] ].copy()\n",
    "\n",
    "f.columns = ['Job',             'Salary'      ,'Location',        'Via',                'Home',                   'DTC'           , 'Rate',           'Company'     ,'job_skills','Skills'      , 'Country']\n",
    "\n",
    "print(f.head(5).to_string())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SInot1wEgO3p",
    "outputId": "f47122f1-5354-4bfa-fef0-7da0221f2207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                   Job  Salary                      Location               Via   Home                  DTC  Rate                     Company                                              job_skills  Skills        Country                  DT Month  Year\n",
      "0      0  Senior Data Engineer     NaN                 Watertown, CT   via Work Nearby  False  2023-06-16 13:44:15  None        Boehringer Ingelheim                                                    None    None  United States 2023-06-16 13:44:15    06  2023\n",
      "1      1          Data Analyst     NaN  Guadalajara, Jalisco, Mexico  via BeBee México  False  2023-01-14 13:18:07  None  Hewlett Packard Enterprise  ['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']       r         Mexico 2023-01-14 13:18:07    01  2023\n",
      "2      2          Data Analyst     NaN  Guadalajara, Jalisco, Mexico  via BeBee México  False  2023-01-14 13:18:07  None  Hewlett Packard Enterprise  ['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']  python         Mexico 2023-01-14 13:18:07    01  2023\n",
      "3      3          Data Analyst     NaN  Guadalajara, Jalisco, Mexico  via BeBee México  False  2023-01-14 13:18:07  None  Hewlett Packard Enterprise  ['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']     sql         Mexico 2023-01-14 13:18:07    01  2023\n",
      "4      4          Data Analyst     NaN  Guadalajara, Jalisco, Mexico  via BeBee México  False  2023-01-14 13:18:07  None  Hewlett Packard Enterprise  ['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']   nosql         Mexico 2023-01-14 13:18:07    01  2023\n"
     ]
    }
   ],
   "source": [
    "# Creating Dates variables\n",
    "g= f.copy()\n",
    "\n",
    "g['DT'] = pd.to_datetime(g['DTC'])\n",
    "\n",
    "g['Month'] = g['DT'].dt.strftime('%B')\n",
    "g['Month'] = g['DT'].dt.strftime('%m')\n",
    "g['Year'] = g['DT'].dt.year\n",
    "g.reset_index(inplace=True)\n",
    "\n",
    "print(g.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3777320 entries, 0 to 3777319\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Dtype         \n",
      "---  ------      -----         \n",
      " 0   index       int64         \n",
      " 1   Job         object        \n",
      " 2   Salary      float64       \n",
      " 3   Location    object        \n",
      " 4   Via         object        \n",
      " 5   Home        bool          \n",
      " 6   DTC         object        \n",
      " 7   Rate        object        \n",
      " 8   Company     object        \n",
      " 9   job_skills  object        \n",
      " 10  Skills      object        \n",
      " 11  Country     object        \n",
      " 12  DT          datetime64[ns]\n",
      " 13  Month       object        \n",
      " 14  Year        int32         \n",
      "dtypes: bool(1), datetime64[ns](1), float64(1), int32(1), int64(1), object(10)\n",
      "memory usage: 392.7+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 120719 entries, 157 to 3777114\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   index       120719 non-null  int64         \n",
      " 1   Job         120719 non-null  object        \n",
      " 2   Salary      120719 non-null  float64       \n",
      " 3   Location    119349 non-null  object        \n",
      " 4   Via         120719 non-null  object        \n",
      " 5   Home        120719 non-null  bool          \n",
      " 6   DTC         120719 non-null  object        \n",
      " 7   Rate        120719 non-null  object        \n",
      " 8   Company     120719 non-null  object        \n",
      " 9   job_skills  118886 non-null  object        \n",
      " 10  Skills      118886 non-null  object        \n",
      " 11  Country     120719 non-null  object        \n",
      " 12  DT          120719 non-null  datetime64[ns]\n",
      " 13  Month       120719 non-null  object        \n",
      " 14  Year        120719 non-null  int32         \n",
      "dtypes: bool(1), datetime64[ns](1), float64(1), int32(1), int64(1), object(10)\n",
      "memory usage: 13.5+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#this will take only the variable at the end with no missing values. we assume missing at random here\n",
    "g.info()\n",
    "h= g[ pd.notna( g['Salary'] ) ].copy()\n",
    "\n",
    "# We forecast the next salary based on an inflation of 3%. This data is from 2023\n",
    "\n",
    "h['Salary']= h['Salary'].apply(lambda salary:salary*1.03)\n",
    "h.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can safely assume that each country in europe has different salary baremas and that skills are paid differently depending on the job title. In other words, knowing an additional language is an important factor for a secretary maybe more than for a programmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xwFvlXZRe6nD"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# The first dt has relation with the variable dt within the dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# the a dataset is the data with the list of the european countries\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestadistico/europe_countries\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m a \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_pandas()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# The first dt has relation with the variable dt within the dataset\n",
    "# the a dataset is the data with the list of the european countries\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('estadistico/europe_countries')\n",
    "a = dataset['train'].to_pandas()\n",
    "\n",
    "print(a.head().to_string())\n",
    "\n",
    "# Selecting all european countries\n",
    "i =pd.merge(h, a, on='Country', how='inner')\n",
    "print(\"#####################################\")\n",
    "print(i.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0uZwCvacRNk",
    "outputId": "68555da6-949a-442a-bd1d-1a2921aabf47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3777320 entries, 0 to 3777319\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Dtype         \n",
      "---  ------      -----         \n",
      " 0   index       int64         \n",
      " 1   Job         object        \n",
      " 2   Salary      float64       \n",
      " 3   Location    object        \n",
      " 4   Via         object        \n",
      " 5   Home        bool          \n",
      " 6   DTC         object        \n",
      " 7   Rate        object        \n",
      " 8   Company     object        \n",
      " 9   job_skills  object        \n",
      " 10  Skills      object        \n",
      " 11  Country     object        \n",
      " 12  DT          datetime64[ns]\n",
      " 13  Month       object        \n",
      " 14  Year        int32         \n",
      "dtypes: bool(1), datetime64[ns](1), float64(1), int32(1), int64(1), object(10)\n",
      "memory usage: 392.7+ MB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6c_NevbCcGBS"
   },
   "outputs": [],
   "source": [
    "\n",
    "j = i[i[\"Analyze\"] == 'Y'].copy()\n",
    "j.to_csv('data/Data_Jobs.csv', sep = ',', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
